---
title: "Ass4_DC"
author: "Daniel Clark"
date: "2023-10-05"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(ggplot2)
library(ranger)
library(glmnet)
library(xgboost)
library(caret)
```

## Task 1

*A*

```{r}
set.seed(502)
```

*B*

```{r}
# Load data
df=read.csv("bank_marketing.csv", sep=";")

```

*C*

The variable 'pdays' should not be considered, as it appears to be coming through with a very large percentage of values at 999, which is unrealistic and is a flaw in the data, so should be removed.

We should also remove the variable 'duration' because, as described in the data dictionary, "last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.". This clearly indicates that it should be removed when creating a predictive model, so that we don't introduce any bias.


## Task 2

*A*

```{r}
# Remove column
df = df %>% mutate(pdays=NULL, duration=NULL)

# Fix up datatypes
df$job = as.factor(df$job)
df$marital = as.factor(df$marital)
df$education = as.factor(df$education)
df$default = as.factor(df$default)
df$contact = as.factor(df$contact)
df$month = as.factor(df$month)
df$day_of_week = as.factor(df$day_of_week)
df$poutcome = as.factor(df$poutcome)

# Code response variable
df$y = as.numeric(ifelse(df$y=="yes", 1, 0))

# Split into training and test
dfyes = filter(df, y==1)
dfno = filter(df, y==0)

numy=count(dfyes)[1,1]
numn=count(dfno)[1,1]
ysamp = sample(numy, numy*0.9)
nsamp = sample(numn,numn*0.9)

train.df = rbind(dfyes[ysamp,], dfno[nsamp,])
test.df = rbind(dfyes[-ysamp,], dfno[-nsamp,])

```

*B and C*

```{r}
# Summary Table of education
df %>% group_by(education) %>% summarise(percent_yes = mean(y)*100)
```

From this visualisation, we can see there is some correlation between education type and the chance of subscribing to a term deposit. However, we do not know if this relationship is causal. We can see that the most likely individuals to subscribe are those with a university degree, or who have not disclosed their education status to the bank. This makes sense as people who have completed university education would tend to earn more and therefore have more disposable income available to invest. Contrastingly, those with only a 'basic' income are far less likely to subscribe for the opposite reason.


```{r}
# Plot
ggplot(data=df, aes(x=age, y=job, col=factor(y))) + geom_jitter(alpha=0.8)

```

From this plot we can see that there is a correlation between someone's job and their likelihood of subscribing. We can tell this because there is a much higher percentage of blue dots for people who are retired, work in admin or management, than for other jobs including being unemployed, a student, a housemaid, or an entrepreneur. We can also see that there is a strong relationship between age and employment status, which indicates age may also be a correlated variable.

```{r}
by_age = group_by(df, age) %>% summarise(m=mean(y))
ggplot(data=by_age, aes(x=age, y=m)) + geom_line()
```

From this graph we can see that the fraction of people who will subscribe to the term deposit appears to be bimodal, with one peak for very young people, quickly dropping down for middle aged (30-60) people, and then increasing to a much higher chance for people 60 years or older.


*D*

I predict that age, education status, and poutcome (whether or not they have subscribed to a term deposit before) will be three of the main predictive variables. The first two I have decided on because of the visualisations, and I chose poutcome because previous behaviour can often indicate future behaviours as well.


## Task 3

*A*

i) Logistic Regression with GLM

```{r}
log_fit = glm(y~., data=train.df)
summary(log_fit)
```

ii) Ridge Regression

```{r}
ridge_fit = glmnet(data.matrix(train.df[,-19]), train.df$y, alpha = 0)

```


iii) Random Forest

```{r}
forest_fit = ranger(y~., data=train.df, importance="impurity")

```



iv) XGBoost

```{r}
# Scale Data and Fit
xgb_train = xgb.DMatrix(data = data.matrix(train.df[, -19]), label = train.df[, 19])
xgb_fit = bst <- xgboost(xgb_train, nrounds=2, objective = "binary:logistic", lambda=1)

```


*B*
Predictions and confusion Matrices

```{r}
#Logistic Regression
log_pred = predict(log_fit, test.df[,-19])
log_pred = ifelse(log_pred<0.5, 0, 1)
# Confusion Matrix
log_conf = confusionMatrix(as.factor(log_pred), as.factor(test.df$y))
log_conf
```


```{r}
#Ridge
ridge_pred = predict(ridge_fit, data.matrix(test.df[,-19]))[,100]
ridge_pred = ifelse(ridge_pred<0.5, 0, 1)
# Confusion Matrix
ridge_conf = confusionMatrix(as.factor(ridge_pred), as.factor(test.df$y))
ridge_conf
```

```{r}
#Random Forest
forest_pred = predict(forest_fit, data.matrix(test.df[,-19]))$predictions
forest_pred = ifelse(forest_pred<0.5, 0, 1)
# Confusion Matrix
forest_conf = confusionMatrix(as.factor(forest_pred), as.factor(test.df$y))
forest_conf
```

```{r}
#XGBoost
xgb_test = xgb.DMatrix(data = data.matrix(test.df[, -19]), label = test.df[, 19])
xgb_pred = predict(xgb_fit, newdata=xgb_test)
xgb_pred = ifelse(xgb_pred<0.5, 0, 1)
# Confusion Matrix
xgb_conf = confusionMatrix(as.factor(xgb_pred), as.factor(test.df$y))
xgb_conf
```

## Task 4 - Compare and Summarise

*A*

Compare 6 most important variables from ranger and xgboost methods

```{r}
# Ranger
forest_imp = forest_fit$variable.importance/sum(forest_fit$variable.importance)*100
forest_imp %>% sort(decreasing=TRUE) %>% head(6)
```

```{r}
# Ranger
xgb_imp = xgb.importance(colnames(train.df[,-19]), model=xgb_fit)
xgb_imp %>% head(6)
```

We can see from these two outputs that the top 6 most important variables in each model are very different. The XGboost model's most important feature is nr_employed, the number of people employed by the company. This is a very surprising feature that we wouldn't expect to have a high importance on whether an individual client subscribes to a term deposit. Perhaps this is a spurious correlation, or maybe there is a more hidden link of causation here. This feature is also the third most important in the ranger (random forest) model so there must be some relation. The ranger model's two most important variables are euribor3m (the 3 month economic forecast) and age, which are both variables that I would expect to be relevant, so it does seem that the models are working correctly.

```{r, message=FALSE}
# Plot of nremplyed vs y
df_empl = group_by(df, nr_employed) %>% summarise("proportion" = mean(y), "num_of_observations" = n())
ggplot(data=df_empl, aes(x=nr_employed, y=proportion)) + geom_point(aes(size=num_of_observations)) + geom_smooth(method="lm", se=FALSE) + ggtitle("Proportion of clients that subscribe, by the number of employees")
```

From this plot we can see that there appears to be a strong negative (approximately linear) relationship between the number of employees and the proportion of clients that subscribe to a term deposit. From the counts that I have displayed, we can see that there are relatively few observations from when there were few employees, compared to a lot of observations with many employees. There may have been a company policy change or another confounding/lurking variable that makes this relationship occur.

*B*

```{r}
misclassification = data.frame(Logistic = 1 - log_conf$overall[1], Ridge = 1 - ridge_conf$overall[1], Ranger = 1 - forest_conf$overall[1], XGBoost = 1 - xgb_conf$overall[1], row.names = "Misclassification Rate")
misclassification
```

Overall, each of the methods have a fairly similar misclassification rate, being around 9%. The model with the lowest misclassification rate is the XGBoost model, followed by Logistic Regression, Ridge Regression, and then Random forest with Ranger. For this reason, I would select the XGBoost model as my preferred model of these 4 options. It is also the second best model at predicting True-True, which is important in this scenario.


*C* 
Suppose you are a Data Scientist working for a bank, and you are tasked to present the results to your marketing manager. Write a short ‘Executive Summary’ paragraph summarising the work in plain English.


I have undertaken a statistical investigation into what factors are the most important when it comes to clients subscribing for a term deposit, and therefore how to maximise the number of clients that choose to purchase term deposits. I have used four statistical modelling approaches to model the situation, including logistic regression, ridge regression, random forests, and boosting methods. These methods all have different pros and cons, but I found the XGboost method to be the most successful when tested on unseen data. From these methods, I have also identified that having LESS employees at the bank appears to be a strong indicator for clients being more likely to apply for a deposit, and that client age, and the Euribor 3 month rate also have a strong correlation. Overall, my best model has a accuracy rate of 90.5% . Another variable that is highly important is the previous outcome (if the client has been with the bank previously), so this can be used to 'target' customers that are more likely to subscribe to a term deposit, for future 'proactive' marketing campaigns.






